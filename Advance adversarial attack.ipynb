{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "864ded98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== IMPROVED ADVERSARIAL AI DETECTION ROBUSTNESS PIPELINE =====\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from deep_translator import GoogleTranslator\n",
    "import string\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "790001ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading omw-en: Package 'omw-en' not found in index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# ===== NLTK Setup (Silent) =====\n",
    "required_nltk = ['punkt', 'punkt_tab', 'wordnet', 'omw-en', 'averaged_perceptron_tagger']\n",
    "for resource in required_nltk:\n",
    "    try:\n",
    "        if resource in ['punkt', 'punkt_tab']:\n",
    "            nltk.data.find(f'tokenizers/{resource}')\n",
    "        elif resource == 'averaged_perceptron_tagger':\n",
    "            nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "        else:\n",
    "            nltk.data.find(f'corpora/{resource}')\n",
    "    except LookupError:\n",
    "        nltk.download(resource, quiet=True)\n",
    "\n",
    "# ===== Groq API Setup =====\n",
    "try:\n",
    "    from groq import Groq\n",
    "    api_key = os.getenv(\"GROQ_API_KEY\", \"your_api_key_here\")\n",
    "    if api_key == \"your_api_key_here\":\n",
    "        print(\"Warning: Please set your Groq API key\")\n",
    "        groq_client = None\n",
    "    else:\n",
    "        groq_client = Groq(api_key=api_key)\n",
    "        print(\"Groq API initialized successfully\")\n",
    "except Exception as e:\n",
    "    groq_client = None\n",
    "    print(f\"Warning: Groq API not available: {e}\")\n",
    "    print(\"Pipeline will work with rule-based transformations only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d47fecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== REALISTIC GENRE-SPECIFIC PATTERNS =====\n",
    "HUMANIZATION_PATTERNS = {\n",
    "    'education': {\n",
    "        'personal_academic': [\"Based on my understanding,\", \"From what I've learned,\", \"In my studies,\", \"From my research,\", \"I believe that\"],\n",
    "        'uncertainty_academic': [\"it seems that\", \"appears to be\", \"might indicate\", \"could suggest\", \"likely demonstrates\"],\n",
    "        'conversational_academic': [\"essentially\", \"basically\", \"in other words\", \"put simply\", \"to clarify\"],\n",
    "        'hedging': [\"somewhat\", \"rather\", \"quite\", \"fairly\", \"relatively\"],\n",
    "        'typos': [(\"separate\", \"seperate\"), (\"definitely\", \"definately\"), (\"occurrence\", \"occurence\"), (\"receive\", \"recieve\")]\n",
    "    },\n",
    "    'creative': {\n",
    "        'personal_expression': [\"I find that\", \"What strikes me is\", \"I've always felt\", \"In my experience\", \"Personally, I think\"],\n",
    "        'emotional_language': [\"beautifully\", \"powerfully\", \"deeply\", \"profoundly\", \"remarkably\"],\n",
    "        'conversational_flow': [\"you know\", \"I mean\", \"honestly\", \"really\", \"actually\"],\n",
    "        'creative_uncertainty': [\"perhaps\", \"maybe\", \"possibly\", \"somehow\", \"in a way\"],\n",
    "        'typos': [(\"rhythm\", \"rythm\"), (\"beautiful\", \"beautifull\"), (\"necessary\", \"neccessary\"), (\"embarrass\", \"embarass\")]\n",
    "    },\n",
    "    'tech': {\n",
    "        'personal_experience': [\"In my work,\", \"From my experience,\", \"I've found that\", \"Working with this,\", \"Personally,\"],\n",
    "        'tech_casual': [\"basically\", \"pretty much\", \"essentially\", \"more or less\", \"kind of\"],\n",
    "        'uncertainty_tech': [\"probably\", \"likely\", \"seems to\", \"appears to\", \"I think\"],\n",
    "        'informal_connectors': [\"Also,\", \"Plus,\", \"But here's the thing,\", \"Now,\", \"So basically,\"],\n",
    "        'typos': [(\"implementation\", \"implimentation\"), (\"algorithm\", \"algorythm\"), (\"configuration\", \"confuguration\")]\n",
    "    }\n",
    "}\n",
    "\n",
    "AI_MIMICRY_PATTERNS = {\n",
    "    'education': {\n",
    "        'academic_starters': [\"Research indicates\", \"Studies demonstrate\", \"Analysis reveals\", \"Evidence suggests\", \"Data shows\"],\n",
    "        'formal_language': [\"demonstrates\", \"indicates\", \"reveals\", \"establishes\", \"manifests\"],\n",
    "        'objective_replacements': [(\"I think\", \"Research suggests\"), (\"In my view\", \"Analysis indicates\"), (\"I believe\", \"Evidence demonstrates\")],\n",
    "        'remove_personal': [(\"personally\", \"objectively\"), (\"I feel\", \"data indicates\"), (\"my experience\", \"research shows\")]\n",
    "    },\n",
    "    'creative': {\n",
    "        'analytical_starters': [\"Examination reveals\", \"Analysis demonstrates\", \"Observation indicates\", \"Assessment shows\"],\n",
    "        'formal_descriptors': [\"exhibits\", \"demonstrates\", \"manifests\", \"displays\", \"presents\"],\n",
    "        'objective_replacements': [(\"I find\", \"Analysis reveals\"), (\"strikes me\", \"demonstrates\"), (\"I've felt\", \"evidence suggests\")],\n",
    "        'remove_emotional': [(\"beautifully\", \"effectively\"), (\"powerfully\", \"significantly\"), (\"deeply\", \"substantially\")]\n",
    "    },\n",
    "    'tech': {\n",
    "        'technical_starters': [\"Implementation demonstrates\", \"System analysis reveals\", \"Technical evaluation shows\", \"Performance data indicates\"],\n",
    "        'precise_language': [\"optimal performance\", \"systematic approach\", \"efficient methodology\", \"comprehensive solution\"],\n",
    "        'objective_replacements': [(\"I've found\", \"Testing demonstrates\"), (\"In my work\", \"Implementation shows\"), (\"personally\", \"technically\")],\n",
    "        'remove_casual': [(\"basically\", \"fundamentally\"), (\"pretty much\", \"approximately\"), (\"kind of\", \"somewhat\")]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ===== GENRE-SPECIFIC ATTACK MAPPING =====\n",
    "GENRE_ATTACK_MAPPING = {\n",
    "    'education': {\n",
    "        'ai_to_human': [\"PersonalAcademic\", \"ConversationalAcademic\", \"SubtleImperfection\"],\n",
    "        'human_to_ai': [\"FormalAcademic\", \"ObjectiveRestructure\", \"PrecisionRewrite\"]\n",
    "    },\n",
    "    'creative': {\n",
    "        'ai_to_human': [\"PersonalExpression\", \"EmotionalStyle\", \"CreativeImperfection\"],\n",
    "        'human_to_ai': [\"AnalyticalStyle\", \"ObjectiveCreative\", \"FormalCreative\"]\n",
    "    },\n",
    "    'tech': {\n",
    "        'ai_to_human': [\"TechExperience\", \"CasualTech\", \"TechImperfection\"],\n",
    "        'human_to_ai': [\"TechnicalPrecision\", \"SystematicApproach\", \"FormalTech\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97337235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== REALISTIC TEXT TRANSFORMATION FUNCTIONS =====\n",
    "\n",
    "def add_realistic_human_touches(text: str, genre: str, intensity: float = 0.7) -> str:\n",
    "    \"\"\"Add realistic human touches without over-formatting\"\"\"\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return text\n",
    "        \n",
    "    genre_key = genre.lower()\n",
    "    if genre_key not in HUMANIZATION_PATTERNS:\n",
    "        genre_key = 'education'\n",
    "    \n",
    "    patterns = HUMANIZATION_PATTERNS[genre_key]\n",
    "    \n",
    "    try:\n",
    "        sentences = sent_tokenize(text)\n",
    "    except:\n",
    "        sentences = text.split('.')\n",
    "        \n",
    "    if not sentences:\n",
    "        return text\n",
    "        \n",
    "    modified_sentences = []\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if not sentence.strip():\n",
    "            continue\n",
    "            \n",
    "        current_sentence = sentence.strip()\n",
    "        \n",
    "        # Add personal touches more naturally (20% chance for subtle, 40% for high)\n",
    "        touch_chance = 0.2 if intensity < 0.8 else 0.4\n",
    "        if random.random() < touch_chance * intensity:\n",
    "            if genre_key == 'education' and 'personal_academic' in patterns:\n",
    "                touch = random.choice(patterns['personal_academic'])\n",
    "                current_sentence = f\"{touch} {current_sentence.lower()}\"\n",
    "            elif genre_key == 'creative' and 'personal_expression' in patterns:\n",
    "                touch = random.choice(patterns['personal_expression'])\n",
    "                current_sentence = f\"{touch} {current_sentence.lower()}\"\n",
    "            elif genre_key == 'tech' and 'personal_experience' in patterns:\n",
    "                touch = random.choice(patterns['personal_experience'])\n",
    "                current_sentence = f\"{touch} {current_sentence.lower()}\"\n",
    "        \n",
    "        # Add conversational elements naturally (15% chance)\n",
    "        elif random.random() < 0.15 * intensity:\n",
    "            if genre_key == 'education' and 'conversational_academic' in patterns:\n",
    "                conv = random.choice(patterns['conversational_academic'])\n",
    "                current_sentence = current_sentence.replace(',', f', {conv},', 1)\n",
    "            elif genre_key == 'creative' and 'conversational_flow' in patterns:\n",
    "                conv = random.choice(patterns['conversational_flow'])\n",
    "                words = current_sentence.split()\n",
    "                if len(words) > 4:\n",
    "                    pos = random.randint(1, min(3, len(words)-1))\n",
    "                    words.insert(pos, f\"{conv},\")\n",
    "                    current_sentence = ' '.join(words)\n",
    "            elif genre_key == 'tech' and 'informal_connectors' in patterns:\n",
    "                conv = random.choice(patterns['informal_connectors'])\n",
    "                current_sentence = f\"{conv} {current_sentence.lower()}\"\n",
    "        \n",
    "        # Add appropriate uncertainty/hedging (10% chance)\n",
    "        elif random.random() < 0.1 * intensity:\n",
    "            if genre_key == 'education' and 'uncertainty_academic' in patterns:\n",
    "                hedge = random.choice(patterns['uncertainty_academic'])\n",
    "                current_sentence = current_sentence.replace(' is ', f' {hedge} ', 1)\n",
    "            elif genre_key == 'creative' and 'creative_uncertainty' in patterns:\n",
    "                hedge = random.choice(patterns['creative_uncertainty'])\n",
    "                current_sentence = current_sentence.replace(' is ', f' is {hedge} ', 1)\n",
    "            elif genre_key == 'tech' and 'uncertainty_tech' in patterns:\n",
    "                hedge = random.choice(patterns['uncertainty_tech'])\n",
    "                current_sentence = current_sentence.replace(' will ', f' {hedge} will ', 1)\n",
    "        \n",
    "        modified_sentences.append(current_sentence)\n",
    "    \n",
    "    if not modified_sentences:\n",
    "        return text\n",
    "        \n",
    "    # Join as single paragraph - NO bullet points or formatting\n",
    "    result = '. '.join(modified_sentences)\n",
    "    if not result.endswith('.'):\n",
    "        result += '.'\n",
    "    \n",
    "    # Add realistic typos sparingly (3% chance for subtle, 8% for high)\n",
    "    typo_chance = 0.03 if intensity < 0.8 else 0.08\n",
    "    if 'typos' in patterns and random.random() < typo_chance:\n",
    "        typo_pair = random.choice(patterns['typos'])\n",
    "        correct, typo = typo_pair\n",
    "        if correct.lower() in result.lower() and random.random() < 0.4:\n",
    "            result = re.sub(re.escape(correct), typo, result, count=1, flags=re.IGNORECASE)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def make_realistically_formal(text: str, genre: str, intensity: float = 0.8) -> str:\n",
    "    \"\"\"Make text more formal without over-doing it\"\"\"\n",
    "    genre_key = genre.lower()\n",
    "    if genre_key not in AI_MIMICRY_PATTERNS:\n",
    "        genre_key = 'education'\n",
    "    \n",
    "    patterns = AI_MIMICRY_PATTERNS[genre_key]\n",
    "    \n",
    "    try:\n",
    "        sentences = sent_tokenize(text)\n",
    "    except:\n",
    "        sentences = text.split('.')\n",
    "    \n",
    "    modified_sentences = []\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if not sentence.strip():\n",
    "            continue\n",
    "            \n",
    "        current_sentence = sentence.strip()\n",
    "        \n",
    "        # Add formal starters to some sentences (25% chance for subtle, 35% for high)\n",
    "        starter_chance = 0.25 if intensity < 0.8 else 0.35\n",
    "        if (random.random() < starter_chance and len(sentence.split()) > 8 and \n",
    "            i == 0 and genre_key in patterns):  # Only first sentence for naturalness\n",
    "            \n",
    "            if genre_key == 'education' and 'academic_starters' in patterns:\n",
    "                starter = random.choice(patterns['academic_starters'])\n",
    "                current_sentence = f\"{starter} that {current_sentence.lower()}\"\n",
    "            elif genre_key == 'creative' and 'analytical_starters' in patterns:\n",
    "                starter = random.choice(patterns['analytical_starters'])\n",
    "                current_sentence = f\"{starter} that {current_sentence.lower()}\"\n",
    "            elif genre_key == 'tech' and 'technical_starters' in patterns:\n",
    "                starter = random.choice(patterns['technical_starters'])\n",
    "                current_sentence = f\"{starter} that {current_sentence.lower()}\"\n",
    "        \n",
    "        modified_sentences.append(current_sentence)\n",
    "    \n",
    "    # Join as single paragraph\n",
    "    result = '. '.join(modified_sentences)\n",
    "    if not result.endswith('.'):\n",
    "        result += '.'\n",
    "    \n",
    "    # Apply objective replacements gradually\n",
    "    if 'objective_replacements' in patterns:\n",
    "        replacement_chance = 0.3 if intensity < 0.8 else 0.5\n",
    "        for old, new in patterns['objective_replacements']:\n",
    "            if old.lower() in result.lower() and random.random() < replacement_chance:\n",
    "                result = re.sub(re.escape(old), new, result, count=1, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove personal/casual language selectively\n",
    "    if 'remove_personal' in patterns:\n",
    "        for old, new in patterns['remove_personal']:\n",
    "            if old.lower() in result.lower() and random.random() < 0.4:\n",
    "                result = re.sub(re.escape(old), new, result, count=1, flags=re.IGNORECASE)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def strategic_paraphrasing_realistic(text: str, target_type: str, genre: str, intensity: float) -> str:\n",
    "    \"\"\"More realistic paraphrasing that maintains natural flow\"\"\"\n",
    "    if groq_client is None:\n",
    "        return text\n",
    "    \n",
    "    try:\n",
    "        # More nuanced prompts based on intensity\n",
    "        if target_type == \"humanize\":\n",
    "            if intensity < 0.8:  # Subtle\n",
    "                prompts = {\n",
    "                    'education': \"Rewrite this academic text to sound like a student or researcher sharing their understanding. Add subtle personal touches like 'from what I understand' but keep it academic. Make it sound natural but scholarly.\",\n",
    "                    'creative': \"Rewrite this to sound like someone personally reflecting on the topic. Add gentle personal observations and natural language, but don't overdo it.\",\n",
    "                    'tech': \"Rewrite this technical content to sound like a developer sharing insights. Add casual phrases like 'I've noticed' but keep the technical accuracy.\"\n",
    "                }\n",
    "            else:  # High intensity but realistic\n",
    "                prompts = {\n",
    "                    'education': \"Rewrite this to sound like a knowledgeable person explaining the concept conversationally. Add personal insights and natural hesitations, making it sound like spoken academic discourse.\",\n",
    "                    'creative': \"Rewrite this with personal voice and emotional engagement, like someone passionate about the topic sharing their thoughts naturally.\",\n",
    "                    'tech': \"Rewrite this as if an experienced developer is explaining it conversationally, with personal examples and informal language, but maintaining technical accuracy.\"\n",
    "                }\n",
    "        else:  # ai_like\n",
    "            if intensity < 0.8:  # Subtle formalization\n",
    "                prompts = {\n",
    "                    'education': \"Make this text slightly more academic and formal. Use more precise language but don't remove all personality. Keep it as one flowing paragraph.\",\n",
    "                    'creative': \"Make this analysis more objective and formal, but not robotic. Use analytical language while maintaining readability as a single paragraph.\",\n",
    "                    'tech': \"Make this more technical and precise. Use formal terminology but keep it readable. Present as one cohesive paragraph.\"\n",
    "                }\n",
    "            else:  # High intensity but not robotic\n",
    "                prompts = {\n",
    "                    'education': \"Rewrite this as formal academic prose. Use objective language and scholarly terminology, but make it read naturally as continuous text.\",\n",
    "                    'creative': \"Transform this into analytical, objective commentary. Remove personal elements and use formal analytical language, but keep natural paragraph flow.\",\n",
    "                    'tech': \"Rewrite this as formal technical documentation. Use precise, professional language and objective tone, maintaining paragraph structure.\"\n",
    "                }\n",
    "        \n",
    "        prompt = prompts.get(genre.lower(), prompts['education'])\n",
    "        \n",
    "        response = groq_client.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"{prompt} IMPORTANT: Keep the output as ONE SINGLE PARAGRAPH with no bullet points, no numbered lists, no section headers, and no special formatting.\"},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            max_tokens=min(1000, len(text.split()) * 2),\n",
    "            temperature=0.5 if intensity < 0.8 else 0.7\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Ensure it's a single paragraph - remove any formatting artifacts\n",
    "        result = re.sub(r'\\n+', ' ', result)  # Remove line breaks\n",
    "        result = re.sub(r'\\*+.*?\\*+', '', result)  # Remove markdown bold\n",
    "        result = re.sub(r'#+\\s*', '', result)  # Remove headers\n",
    "        result = re.sub(r'^\\d+\\.\\s*', '', result)  # Remove numbered lists\n",
    "        result = re.sub(r'^[-*•]\\s*', '', result)  # Remove bullet points\n",
    "        result = re.sub(r'\\s+', ' ', result).strip()  # Clean up spacing\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Paraphrasing failed: {e}\")\n",
    "        return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "952d3678",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gentle_translation(text: str, intensity: float) -> str:\n",
    "    \"\"\"More conservative translation approach\"\"\"\n",
    "    if len(text) > 1200 or intensity < 0.7:  # Skip for long texts or low intensity\n",
    "        return text\n",
    "        \n",
    "    try:\n",
    "        text_to_translate = text[:800] if len(text) > 800 else text\n",
    "        \n",
    "        # Single hop for subtle, double hop for high intensity\n",
    "        if intensity < 0.8:\n",
    "            # Single hop: English -> Spanish -> English\n",
    "            step1 = GoogleTranslator(source='en', target='es').translate(text_to_translate)\n",
    "            if step1:\n",
    "                result = GoogleTranslator(source='es', target='en').translate(step1)\n",
    "                return result if result else text\n",
    "        else:\n",
    "            # Double hop: English -> German -> English\n",
    "            step1 = GoogleTranslator(source='en', target='de').translate(text_to_translate)\n",
    "            if step1:\n",
    "                result = GoogleTranslator(source='de', target='en').translate(step1)\n",
    "                return result if result else text\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Translation failed: {e}\")\n",
    "        return text\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a993e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== IMPROVED ADVERSARIAL ATTACK STRATEGIES =====\n",
    "\n",
    "def realistic_adversarial_attack(text: str, source_label: str, genre: str, attack_type: str, intensity: float) -> Tuple[str, str]:\n",
    "    \"\"\"Execute realistic adversarial attacks based on genre-specific mapping\"\"\"\n",
    "    \n",
    "    source_lower = source_label.lower()\n",
    "    genre_lower = genre.lower()\n",
    "    \n",
    "    # Map broad genres to our categories\n",
    "    if 'education' in genre_lower or 'academic' in genre_lower or 'essay' in genre_lower or 'research' in genre_lower:\n",
    "        mapped_genre = 'education'\n",
    "    elif 'creative' in genre_lower or 'poem' in genre_lower or 'story' in genre_lower or 'history' in genre_lower:\n",
    "        mapped_genre = 'creative'  \n",
    "    elif 'tech' in genre_lower or 'article' in genre_lower or 'review' in genre_lower:\n",
    "        mapped_genre = 'tech'\n",
    "    else:\n",
    "        mapped_genre = 'education'  # default fallback\n",
    "    \n",
    "    if source_lower == 'ai':\n",
    "        # FALSE NEGATIVE attacks: Make AI text appear human-written\n",
    "        \n",
    "        if attack_type == \"PersonalAcademic\" and mapped_genre == 'education':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"humanize\", mapped_genre, intensity)\n",
    "            step2 = add_realistic_human_touches(step1, mapped_genre, intensity)\n",
    "            return step2, \"Personal_Academic_Voice\"\n",
    "        \n",
    "        elif attack_type == \"ConversationalAcademic\" and mapped_genre == 'education':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity)\n",
    "            step2 = gentle_translation(step1, intensity) if intensity > 0.7 else step1\n",
    "            return step2, \"Conversational_Academic\"\n",
    "        \n",
    "        elif attack_type == \"SubtleImperfection\" and mapped_genre == 'education':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity * 0.8)\n",
    "            return step1, \"Subtle_Academic_Imperfection\"\n",
    "        \n",
    "        elif attack_type == \"PersonalExpression\" and mapped_genre == 'creative':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"humanize\", mapped_genre, intensity)\n",
    "            step2 = add_realistic_human_touches(step1, mapped_genre, intensity)\n",
    "            return step2, \"Personal_Creative_Expression\"\n",
    "        \n",
    "        elif attack_type == \"EmotionalStyle\" and mapped_genre == 'creative':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity)\n",
    "            return step1, \"Emotional_Creative_Style\"\n",
    "        \n",
    "        elif attack_type == \"CreativeImperfection\" and mapped_genre == 'creative':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity * 0.7)\n",
    "            return step1, \"Creative_Human_Imperfection\"\n",
    "        \n",
    "        elif attack_type == \"TechExperience\" and mapped_genre == 'tech':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"humanize\", mapped_genre, intensity)\n",
    "            step2 = add_realistic_human_touches(step1, mapped_genre, intensity)\n",
    "            return step2, \"Technical_Experience_Voice\"\n",
    "        \n",
    "        elif attack_type == \"CasualTech\" and mapped_genre == 'tech':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity)\n",
    "            return step1, \"Casual_Technical_Style\"\n",
    "        \n",
    "        elif attack_type == \"TechImperfection\" and mapped_genre == 'tech':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity * 0.8)\n",
    "            return step1, \"Technical_Human_Imperfection\"\n",
    "    \n",
    "    else:  # source_lower == 'human'\n",
    "        # FALSE POSITIVE attacks: Make human text appear AI-generated\n",
    "        \n",
    "        if attack_type == \"FormalAcademic\" and mapped_genre == 'education':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"ai_like\", mapped_genre, intensity)\n",
    "            step2 = make_realistically_formal(step1, mapped_genre, intensity)\n",
    "            return step2, \"Formal_Academic_Style\"\n",
    "        \n",
    "        elif attack_type == \"ObjectiveRestructure\" and mapped_genre == 'education':\n",
    "            step1 = make_realistically_formal(text, mapped_genre, intensity)\n",
    "            step2 = gentle_translation(step1, intensity) if intensity > 0.7 else step1\n",
    "            return step2, \"Objective_Academic_Restructure\"\n",
    "        \n",
    "        elif attack_type == \"PrecisionRewrite\" and mapped_genre == 'education':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"ai_like\", mapped_genre, intensity)\n",
    "            return step1, \"Precision_Academic_Rewrite\"\n",
    "        \n",
    "        elif attack_type == \"AnalyticalStyle\" and mapped_genre == 'creative':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"ai_like\", mapped_genre, intensity)\n",
    "            step2 = make_realistically_formal(step1, mapped_genre, intensity)\n",
    "            return step2, \"Analytical_Creative_Style\"\n",
    "        \n",
    "        elif attack_type == \"ObjectiveCreative\" and mapped_genre == 'creative':\n",
    "            step1 = make_realistically_formal(text, mapped_genre, intensity)\n",
    "            return step1, \"Objective_Creative_Analysis\"\n",
    "        \n",
    "        elif attack_type == \"FormalCreative\" and mapped_genre == 'creative':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"ai_like\", mapped_genre, intensity)\n",
    "            return step1, \"Formal_Creative_Analysis\"\n",
    "        \n",
    "        elif attack_type == \"TechnicalPrecision\" and mapped_genre == 'tech':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"ai_like\", mapped_genre, intensity)\n",
    "            step2 = make_realistically_formal(step1, mapped_genre, intensity)\n",
    "            return step2, \"Technical_Precision_Enhancement\"\n",
    "        \n",
    "        elif attack_type == \"SystematicApproach\" and mapped_genre == 'tech':\n",
    "            step1 = make_realistically_formal(text, mapped_genre, intensity)\n",
    "            return step1, \"Systematic_Technical_Approach\"\n",
    "        \n",
    "        elif attack_type == \"FormalTech\" and mapped_genre == 'tech':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"ai_like\", mapped_genre, intensity)\n",
    "            return step1, \"Formal_Technical_Style\"\n",
    "    \n",
    "    return text, \"No_Attack_Applied\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "792174bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MAIN PROCESSING PIPELINE =====\n",
    "\n",
    "def process_adversarial_dataset(input_file: str, output_file: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main pipeline for generating realistic adversarial samples\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load dataset\n",
    "    try:\n",
    "        if input_file.endswith('.xlsx'):\n",
    "            df = pd.read_excel(input_file)\n",
    "        else:\n",
    "            df = pd.read_csv(input_file)\n",
    "        print(f\"Loaded dataset: {len(df)} samples\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {input_file}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Validate required columns\n",
    "    required_columns = ['original_text', 'source', 'genre']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"Error: Missing required columns: {missing_columns}\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        return None\n",
    "    \n",
    "    # Clean and validate data\n",
    "    df = df.dropna(subset=['original_text', 'source', 'genre'])\n",
    "    df['source'] = df['source'].str.lower().str.strip()\n",
    "    df['genre'] = df['genre'].str.lower().str.strip()\n",
    "    \n",
    "    # Filter valid sources\n",
    "    valid_sources = df['source'].isin(['ai', 'human'])\n",
    "    if not valid_sources.all():\n",
    "        invalid_count = (~valid_sources).sum()\n",
    "        print(f\"Warning: {invalid_count} samples have invalid source labels. Filtering them out.\")\n",
    "        df = df[valid_sources].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Final dataset: {len(df)} samples\")\n",
    "    \n",
    "    # Initialize result columns\n",
    "    result_columns = {\n",
    "        'adversarial_text': \"\",\n",
    "        'attack_type': \"\",\n",
    "        'attack_technique': \"\",\n",
    "        'attack_target': \"\",\n",
    "        'original_length': 0,\n",
    "        'adversarial_length': 0,\n",
    "        'length_change_pct': 0.0,\n",
    "        'modification_intensity': \"\",\n",
    "        'expected_impact': \"\"\n",
    "    }\n",
    "    \n",
    "    for col, default_val in result_columns.items():\n",
    "        df[col] = default_val\n",
    "    \n",
    "    # Process each sample\n",
    "    print(\"Processing samples...\")\n",
    "    successful_attacks = 0\n",
    "    \n",
    "    for idx in df.index:\n",
    "        try:\n",
    "            original_text = str(df.at[idx, 'original_text'])\n",
    "            source = str(df.at[idx, 'source']).strip().lower()\n",
    "            genre = str(df.at[idx, 'genre']).strip().lower()\n",
    "            \n",
    "            # Skip if text is too short or too long\n",
    "            if len(original_text.split()) < 15:\n",
    "                df.at[idx, 'adversarial_text'] = original_text\n",
    "                df.at[idx, 'attack_type'] = \"Text_Too_Short\"\n",
    "                continue\n",
    "            elif len(original_text.split()) > 500:\n",
    "                df.at[idx, 'adversarial_text'] = original_text\n",
    "                df.at[idx, 'attack_type'] = \"Text_Too_Long\"  \n",
    "                continue\n",
    "            \n",
    "            # Map genre to our categories\n",
    "            if 'education' in genre or 'academic' in genre or 'essay' in genre or 'research' in genre:\n",
    "                mapped_genre = 'education'\n",
    "            elif 'creative' in genre or 'poem' in genre or 'story' in genre or 'history' in genre:\n",
    "                mapped_genre = 'creative'  \n",
    "            elif 'tech' in genre or 'article' in genre or 'review' in genre:\n",
    "                mapped_genre = 'tech'\n",
    "            else:\n",
    "                mapped_genre = 'education'  # default\n",
    "            \n",
    "            # Select genre-appropriate attack strategy\n",
    "            if source == 'ai':\n",
    "                available_attacks = GENRE_ATTACK_MAPPING[mapped_genre]['ai_to_human']\n",
    "                target = \"False_Negative\"\n",
    "            else:  # source == 'human'\n",
    "                available_attacks = GENRE_ATTACK_MAPPING[mapped_genre]['human_to_ai']\n",
    "                target = \"False_Positive\"\n",
    "            \n",
    "            attack_type = random.choice(available_attacks)\n",
    "            \n",
    "            # Determine intensity based on text characteristics\n",
    "            word_count = len(original_text.split())\n",
    "            if word_count > 100:\n",
    "                intensity = random.choice([0.6, 0.7, 0.8])  # More conservative for longer texts\n",
    "            else:\n",
    "                intensity = random.choice([0.7, 0.8, 0.9])  # Can be more aggressive for shorter texts\n",
    "            \n",
    "            # Execute realistic adversarial attack\n",
    "            adversarial_text, technique_used = realistic_adversarial_attack(\n",
    "                original_text, source, mapped_genre, attack_type, intensity\n",
    "            )\n",
    "            \n",
    "            # Calculate metrics\n",
    "            orig_length = len(original_text.split())\n",
    "            adv_length = len(adversarial_text.split())\n",
    "            length_change_pct = ((adv_length - orig_length) / orig_length) * 100\n",
    "            \n",
    "            # Determine modification intensity based on both length change and actual intensity\n",
    "            if intensity >= 0.8 and abs(length_change_pct) > 15:\n",
    "                intensity_label = \"High\"\n",
    "            elif intensity >= 0.7 or abs(length_change_pct) > 8:\n",
    "                intensity_label = \"Moderate\"\n",
    "            else:\n",
    "                intensity_label = \"Subtle\"\n",
    "            \n",
    "            # Expected impact assessment\n",
    "            if intensity_label == \"High\" and technique_used != \"No_Attack_Applied\":\n",
    "                impact = \"Strong_Realistic_Challenge\"\n",
    "            elif intensity_label == \"Moderate\":\n",
    "                impact = \"Moderate_Natural_Challenge\"\n",
    "            else:\n",
    "                impact = \"Subtle_Pattern_Shift\"\n",
    "            \n",
    "            # Store results\n",
    "            df.at[idx, 'adversarial_text'] = adversarial_text\n",
    "            df.at[idx, 'attack_type'] = attack_type\n",
    "            df.at[idx, 'attack_technique'] = technique_used\n",
    "            df.at[idx, 'attack_target'] = target\n",
    "            df.at[idx, 'original_length'] = orig_length\n",
    "            df.at[idx, 'adversarial_length'] = adv_length\n",
    "            df.at[idx, 'length_change_pct'] = round(length_change_pct, 2)\n",
    "            df.at[idx, 'modification_intensity'] = intensity_label\n",
    "            df.at[idx, 'expected_impact'] = impact\n",
    "            \n",
    "            if technique_used != \"No_Attack_Applied\":\n",
    "                successful_attacks += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {idx}: {e}\")\n",
    "            df.at[idx, 'adversarial_text'] = df.at[idx, 'original_text']\n",
    "            df.at[idx, 'attack_type'] = \"Processing_Error\"\n",
    "            df.at[idx, 'attack_technique'] = f\"Error: {str(e)[:50]}\"\n",
    "    \n",
    "    # Save results\n",
    "    if output_file is None:\n",
    "        base_name = input_file.rsplit('.', 1)[0]\n",
    "        output_file = f\"{base_name}_realistic_adversarial_results.xlsx\"\n",
    "    \n",
    "    try:\n",
    "        df.to_excel(output_file, index=False)\n",
    "        print(f\"Results saved to: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving file: {e}\")\n",
    "        return df\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    print(\"\\n=== REALISTIC ADVERSARIAL PIPELINE SUMMARY ===\")\n",
    "    print(f\"Total samples processed: {len(df)}\")\n",
    "    print(f\"Successful attacks: {successful_attacks}\")\n",
    "    print(f\"Success rate: {(successful_attacks/len(df)*100):.1f}%\")\n",
    "    \n",
    "    # Attack distribution by genre\n",
    "    print(f\"\\nGenre-specific attack distribution:\")\n",
    "    genre_attack = df.groupby(['genre', 'attack_type']).size().reset_index(name='count')\n",
    "    for genre in df['genre'].unique():\n",
    "        genre_data = genre_attack[genre_attack['genre'] == genre]\n",
    "        print(f\"\\n  {genre.upper()}:\")\n",
    "        for _, row in genre_data.iterrows():\n",
    "            print(f\"    {row['attack_type']}: {row['count']}\")\n",
    "    \n",
    "    # Target distribution\n",
    "    print(f\"\\nAttack target distribution:\")\n",
    "    target_counts = df['attack_target'].value_counts()\n",
    "    for target, count in target_counts.items():\n",
    "        print(f\"  {target}: {count}\")\n",
    "    \n",
    "    # Intensity distribution\n",
    "    print(f\"\\nModification intensity distribution:\")\n",
    "    intensity_counts = df['modification_intensity'].value_counts()\n",
    "    for intensity, count in intensity_counts.items():\n",
    "        print(f\"  {intensity}: {count}\")\n",
    "    \n",
    "    # Sample some results for quality check\n",
    "    print(f\"\\n=== SAMPLE TRANSFORMATIONS ===\")\n",
    "    sample_indices = df.sample(min(3, len(df))).index\n",
    "    for idx in sample_indices:\n",
    "        print(f\"\\nSample {idx} ({df.at[idx, 'genre']} - {df.at[idx, 'source']} -> {df.at[idx, 'attack_type']}):\")\n",
    "        print(f\"Original: {df.at[idx, 'original_text'][:100]}...\")\n",
    "        print(f\"Adversarial: {df.at[idx, 'adversarial_text'][:100]}...\")\n",
    "        print(f\"Technique: {df.at[idx, 'attack_technique']}\")\n",
    "    \n",
    "    print(f\"\\n=== READY FOR REALISTIC AI DETECTOR TESTING ===\")\n",
    "    print(\"✓ Genre-appropriate attacks applied\")\n",
    "    print(\"✓ Single paragraph format maintained\")\n",
    "    print(\"✓ Natural, realistic transformations\")\n",
    "    print(\"✓ Mimics real-world editing scenarios\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a43dab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== MAIN EXECUTION FUNCTION =====\n",
    "\n",
    "def run_realistic_adversarial_pipeline(input_file: str):\n",
    "    \"\"\"\n",
    "    Execute the improved adversarial pipeline for realistic AI detection testing\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to Excel/CSV file with columns: original_text, source, genre\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with original and realistically modified adversarial samples\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== REALISTIC ADVERSARIAL AI DETECTION PIPELINE ===\")\n",
    "    print(\"Purpose: Generate realistic adversarial samples mimicking real-world scenarios\")\n",
    "    print(\"Features:\")\n",
    "    print(\"• Genre-specific attack strategies\")\n",
    "    print(\"• Single paragraph format preservation\")\n",
    "    print(\"• Natural editing patterns\")\n",
    "    print(\"• Realistic intensity levels\")\n",
    "    print(f\"Input file: {input_file}\")\n",
    "    \n",
    "    # Process the dataset\n",
    "    result_df = process_adversarial_dataset(input_file)\n",
    "    \n",
    "    if result_df is not None:\n",
    "        print(\"\\n✓ Realistic pipeline completed successfully\")\n",
    "        print(\"✓ Natural transformations applied\")\n",
    "        print(\"✓ Ready for detector robustness evaluation\")\n",
    "        print(\"✓ Dataset prepared for real-world scenario testing\")\n",
    "        return result_df\n",
    "    else:\n",
    "        print(\"\\n✗ Pipeline failed - please check input file and requirements\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "841b936c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALISTIC ADVERSARIAL AI DETECTION PIPELINE ===\n",
      "Purpose: Generate realistic adversarial samples mimicking real-world scenarios\n",
      "Features:\n",
      "• Genre-specific attack strategies\n",
      "• Single paragraph format preservation\n",
      "• Natural editing patterns\n",
      "• Realistic intensity levels\n",
      "Input file: Sample.xlsx\n",
      "Loaded dataset: 300 samples\n",
      "Final dataset: 300 samples\n",
      "Processing samples...\n",
      "Results saved to: Sample_realistic_adversarial_results.xlsx\n",
      "\n",
      "=== REALISTIC ADVERSARIAL PIPELINE SUMMARY ===\n",
      "Total samples processed: 300\n",
      "Successful attacks: 300\n",
      "Success rate: 100.0%\n",
      "\n",
      "Genre-specific attack distribution:\n",
      "\n",
      "  TECH:\n",
      "    CasualTech: 13\n",
      "    FormalTech: 12\n",
      "    SystematicApproach: 14\n",
      "    TechExperience: 21\n",
      "    TechImperfection: 16\n",
      "    TechnicalPrecision: 24\n",
      "\n",
      "  EDUCATION:\n",
      "    ConversationalAcademic: 12\n",
      "    FormalAcademic: 18\n",
      "    ObjectiveRestructure: 20\n",
      "    PersonalAcademic: 28\n",
      "    PrecisionRewrite: 12\n",
      "    SubtleImperfection: 10\n",
      "\n",
      "  CREATIVES:\n",
      "    AnalyticalStyle: 20\n",
      "    CreativeImperfection: 23\n",
      "    EmotionalStyle: 16\n",
      "    FormalCreative: 17\n",
      "    ObjectiveCreative: 13\n",
      "    PersonalExpression: 11\n",
      "\n",
      "Attack target distribution:\n",
      "  False_Positive: 150\n",
      "  False_Negative: 150\n",
      "\n",
      "Modification intensity distribution:\n",
      "  Moderate: 216\n",
      "  Subtle: 54\n",
      "  High: 30\n",
      "\n",
      "=== SAMPLE TRANSFORMATIONS ===\n",
      "\n",
      "Sample 159 (education - ai -> PersonalAcademic):\n",
      "Original: The Cold War in Realism Theory is a significant area of study and research. In the modern world, thi...\n",
      "Adversarial: I believe that from what i understand, the study of the cold war in the context of realism theory ha...\n",
      "Technique: Personal_Academic_Voice\n",
      "\n",
      "Sample 145 (education - ai -> ConversationalAcademic):\n",
      "Original: Ancient Ways of Communication Before Technology is a significant area of study and research. In the ...\n",
      "Adversarial: Ancient Ways of Communication Before Technology is a significant area of study and research.. In the...\n",
      "Technique: Conversational_Academic\n",
      "\n",
      "Sample 292 (creatives - human -> AnalyticalStyle):\n",
      "Original: The Sāṅkhya or Sāṁkhya philosophy enjoys a unique and prime position in the history of evolution and...\n",
      "Adversarial: The Sāṅkhya philosophy occupies a distinct and pivotal position within the historical development of...\n",
      "Technique: Analytical_Creative_Style\n",
      "\n",
      "=== READY FOR REALISTIC AI DETECTOR TESTING ===\n",
      "✓ Genre-appropriate attacks applied\n",
      "✓ Single paragraph format maintained\n",
      "✓ Natural, realistic transformations\n",
      "✓ Mimics real-world editing scenarios\n",
      "\n",
      "✓ Realistic pipeline completed successfully\n",
      "✓ Natural transformations applied\n",
      "✓ Ready for detector robustness evaluation\n",
      "✓ Dataset prepared for real-world scenario testing\n",
      "\n",
      "=== QUALITY CHECK ===\n",
      "\n",
      "High-intensity sample:\n",
      "Genre: tech\n",
      "Source: human\n",
      "Attack: TechnicalPrecision\n",
      "Original: Regardless of what flavor of blockchain wins in the end, the smart contracts that will run on it will need a variety of supporting technologies. These supplementary technologies are now being developed, to little fanfare, in the shadow of the blockchain carnival. And they will be absolutely crucial to the expansion of blockchain technology.“Once you’ve got smart contracts, a whole host of problems arise,” says Ari Juels, a codirector of Cornell University’s IC3. These problems fall into a couple of categories.For one thing, blockchains can’t store much data. That’s going to be a problem for the many projects that, for example, propose to live-stream video over the blockchain—there’s nowhere to put the video content.The Bitcoin blockchain records the inputs and outputs of every coin on the network, as well as the content of an additional field that allows for up to a mere 40 bytes of metadata per transaction. That’s all.Another problem with putting contracts on blockchains is that blockchains by themselves don’t know what’s going on in the real world. That’s a problem if, say, your smart contract is a flight insurance system, because it needs to know when your flight really takes off and lands. Blockchains were never designed to query websites. “Anything they learn about the outside world has to be injected into them,” says IC3’s Juels.\n",
      "Modified: The development and deployment of smart contracts on various blockchain platforms necessitate a suite of complementary technologies to address the inherent limitations and challenges of blockchain technology.. While the blockchain itself is capable of recording and verifying transactions, it lacks the capacity to store significant amounts of data, posing a substantial problem for applications that require the storage of large datasets, such as live-streamed video content.. The Bitcoin blockchain, for example, is restricted to recording inputs and outputs of every coin on the network, along with a maximum of 40 bytes of metadata per transaction.. Furthermore, blockchains are not equipped with the ability to query external sources or gather information from the real world, presenting a significant obstacle for smart contracts that rely on real-time data, such as flight insurance systems that require knowledge of flight schedules and departure/arrival times.. As a result, the integration of blockchain technology with supplementary systems capable of injecting external data and facilitating data storage will be crucial to the advancement and widespread adoption of blockchain-based smart contracts.\n",
      "Change: -21.36%\n",
      "\n",
      "Formatting quality check: 270/300 samples properly formatted\n",
      "⚠️  30 samples may have formatting artifacts\n"
     ]
    }
   ],
   "source": [
    "# ===== USAGE EXAMPLE =====\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage - replace with your actual file\n",
    "    input_filename = \"Sample.xlsx\"  # Your dataset file\n",
    "    results = run_realistic_adversarial_pipeline(input_filename)\n",
    "    \n",
    "    # Optional: Check specific transformations\n",
    "    if results is not None:\n",
    "        print(\"\\n=== QUALITY CHECK ===\")\n",
    "        # Show high-intensity transformations\n",
    "        high_intensity = results[results['modification_intensity'] == 'High']\n",
    "        if len(high_intensity) > 0:\n",
    "            print(f\"\\nHigh-intensity sample:\")\n",
    "            idx = high_intensity.index[0]\n",
    "            print(f\"Genre: {results.at[idx, 'genre']}\")\n",
    "            print(f\"Source: {results.at[idx, 'source']}\")\n",
    "            print(f\"Attack: {results.at[idx, 'attack_type']}\")\n",
    "            print(f\"Original: {results.at[idx, 'original_text']}\")\n",
    "            print(f\"Modified: {results.at[idx, 'adversarial_text']}\")\n",
    "            print(f\"Change: {results.at[idx, 'length_change_pct']}%\")\n",
    "        \n",
    "        # Check for any formatting issues\n",
    "        formatting_issues = 0\n",
    "        for idx in results.index:\n",
    "            adv_text = str(results.at[idx, 'adversarial_text'])\n",
    "            if ('*' in adv_text or '#' in adv_text or \n",
    "                adv_text.count('\\n') > 2 or '1.' in adv_text or '•' in adv_text):\n",
    "                formatting_issues += 1\n",
    "        \n",
    "        print(f\"\\nFormatting quality check: {len(results) - formatting_issues}/{len(results)} samples properly formatted\")\n",
    "        if formatting_issues > 0:\n",
    "            print(f\"⚠️  {formatting_issues} samples may have formatting artifacts\")\n",
    "        else:\n",
    "            print(\"✓ All samples maintain single paragraph format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75d802e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Parrot)",
   "language": "python",
   "name": "parrot_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
