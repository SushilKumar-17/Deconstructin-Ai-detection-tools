{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a62703d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== IMPROVED ADVERSARIAL AI DETECTION ROBUSTNESS PIPELINE =====\n",
    "import pandas as pd\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from deep_translator import GoogleTranslator\n",
    "import string\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d8c06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading omw-en: Package 'omw-en' not found in index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# ===== NLTK Setup (Silent) =====\n",
    "required_nltk = ['punkt', 'punkt_tab', 'wordnet', 'omw-en', 'averaged_perceptron_tagger']\n",
    "for resource in required_nltk:\n",
    "    try:\n",
    "        if resource in ['punkt', 'punkt_tab']:\n",
    "            nltk.data.find(f'tokenizers/{resource}')\n",
    "        elif resource == 'averaged_perceptron_tagger':\n",
    "            nltk.data.find('taggers/averaged_perceptron_tagger')\n",
    "        else:\n",
    "            nltk.data.find(f'corpora/{resource}')\n",
    "    except LookupError:\n",
    "        nltk.download(resource, quiet=True)\n",
    "\n",
    "# ===== Groq API Setup =====\n",
    "try:\n",
    "    from groq import Groq\n",
    "    api_key = os.getenv(\"GROQ_API_KEY\", \"your_api_key_here\")\n",
    "    if api_key == \"your_api_key_here\":\n",
    "        print(\"Warning: Please set your Groq API key\")\n",
    "        groq_client = None\n",
    "    else:\n",
    "        groq_client = Groq(api_key=api_key)\n",
    "        print(\"Groq API initialized successfully\")\n",
    "except Exception as e:\n",
    "    groq_client = None\n",
    "    print(f\"Warning: Groq API not available: {e}\")\n",
    "    print(\"Pipeline will work with rule-based transformations only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "124240cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== REALISTIC GENRE-SPECIFIC PATTERNS =====\n",
    "HUMANIZATION_PATTERNS = {\n",
    "    'education': {\n",
    "        'personal_academic': [\"Based on my understanding,\", \"From what I've learned,\", \"In my studies,\", \"From my research,\", \"I believe that\"],\n",
    "        'uncertainty_academic': [\"it seems that\", \"appears to be\", \"might indicate\", \"could suggest\", \"likely demonstrates\"],\n",
    "        'conversational_academic': [\"essentially\", \"basically\", \"in other words\", \"put simply\", \"to clarify\"],\n",
    "        'hedging': [\"somewhat\", \"rather\", \"quite\", \"fairly\", \"relatively\"],\n",
    "        'typos': [(\"separate\", \"seperate\"), (\"definitely\", \"definately\"), (\"occurrence\", \"occurence\"), (\"receive\", \"recieve\")]\n",
    "    },\n",
    "    'creative': {\n",
    "        'personal_expression': [\"I find that\", \"What strikes me is\", \"I've always felt\", \"In my experience\", \"Personally, I think\"],\n",
    "        'emotional_language': [\"beautifully\", \"powerfully\", \"deeply\", \"profoundly\", \"remarkably\"],\n",
    "        'conversational_flow': [\"you know\", \"I mean\", \"honestly\", \"really\", \"actually\"],\n",
    "        'creative_uncertainty': [\"perhaps\", \"maybe\", \"possibly\", \"somehow\", \"in a way\"],\n",
    "        'typos': [(\"rhythm\", \"rythm\"), (\"beautiful\", \"beautifull\"), (\"necessary\", \"neccessary\"), (\"embarrass\", \"embarass\")]\n",
    "    },\n",
    "    'tech': {\n",
    "        'personal_experience': [\"In my work,\", \"From my experience,\", \"I've found that\", \"Working with this,\", \"Personally,\"],\n",
    "        'tech_casual': [\"basically\", \"pretty much\", \"essentially\", \"more or less\", \"kind of\"],\n",
    "        'uncertainty_tech': [\"probably\", \"likely\", \"seems to\", \"appears to\", \"I think\"],\n",
    "        'informal_connectors': [\"Also,\", \"Plus,\", \"But here's the thing,\", \"Now,\", \"So basically,\"],\n",
    "        'typos': [(\"implementation\", \"implimentation\"), (\"algorithm\", \"algorythm\"), (\"configuration\", \"confuguration\")]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ===== UPDATED AI-MIMICRY PATTERNS - MUCH MORE CONSERVATIVE =====\n",
    "AI_MIMICRY_PATTERNS = {\n",
    "    'education': {\n",
    "        'subtle_replacements': [(\"I think\", \"It appears\"), (\"I believe\", \"Evidence suggests\"), (\"personally\", \"\")],\n",
    "        'remove_casual': [(\"you know\", \"\"), (\"I mean\", \"\"), (\"basically\", \"essentially\")],\n",
    "    },\n",
    "    'creative': {\n",
    "        'subtle_replacements': [(\"I find\", \"This reveals\"), (\"strikes me\", \"demonstrates\")],\n",
    "        'tone_down': [(\"beautifully\", \"effectively\"), (\"powerfully\", \"significantly\")],\n",
    "        'remove_casual': [(\"you know\", \"\"), (\"honestly\", \"\"), (\"really\", \"\")]\n",
    "    },\n",
    "    'tech': {\n",
    "        'subtle_replacements': [(\"I've found\", \"Testing shows\"), (\"In my work\", \"Implementation demonstrates\")],\n",
    "        'remove_casual': [(\"basically\", \"essentially\"), (\"pretty much\", \"largely\"), (\"you know\", \"\")],\n",
    "        'neutral_language': [(\"kind of\", \"somewhat\"), (\"sort of\", \"rather\")]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ===== GENRE-SPECIFIC ATTACK MAPPING =====\n",
    "GENRE_ATTACK_MAPPING = {\n",
    "    'education': {\n",
    "        'ai_to_human': [\"PersonalAcademic\", \"ConversationalAcademic\", \"SubtleImperfection\"],\n",
    "        'human_to_ai': [\"FormalAcademic\", \"ObjectiveRestructure\", \"PrecisionRewrite\"]\n",
    "    },\n",
    "    'creative': {\n",
    "        'ai_to_human': [\"PersonalExpression\", \"EmotionalStyle\", \"CreativeImperfection\"],\n",
    "        'human_to_ai': [\"AnalyticalStyle\", \"ObjectiveCreative\", \"FormalCreative\"]\n",
    "    },\n",
    "    'tech': {\n",
    "        'ai_to_human': [\"TechExperience\", \"CasualTech\", \"TechImperfection\"],\n",
    "        'human_to_ai': [\"TechnicalPrecision\", \"SystematicApproach\", \"FormalTech\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# ===== REALISTIC TEXT TRANSFORMATION FUNCTIONS =====\n",
    "\n",
    "def add_realistic_human_touches(text: str, genre: str, intensity: float = 0.7) -> str:\n",
    "    \"\"\"Add realistic human touches without over-formatting\"\"\"\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return text\n",
    "        \n",
    "    genre_key = genre.lower()\n",
    "    if genre_key not in HUMANIZATION_PATTERNS:\n",
    "        genre_key = 'education'\n",
    "    \n",
    "    patterns = HUMANIZATION_PATTERNS[genre_key]\n",
    "    \n",
    "    try:\n",
    "        sentences = sent_tokenize(text)\n",
    "    except:\n",
    "        sentences = text.split('.')\n",
    "        \n",
    "    if not sentences:\n",
    "        return text\n",
    "        \n",
    "    modified_sentences = []\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if not sentence.strip():\n",
    "            continue\n",
    "            \n",
    "        current_sentence = sentence.strip()\n",
    "        \n",
    "        # Add personal touches more naturally (20% chance for subtle, 40% for high)\n",
    "        touch_chance = 0.2 if intensity < 0.8 else 0.4\n",
    "        if random.random() < touch_chance * intensity:\n",
    "            if genre_key == 'education' and 'personal_academic' in patterns:\n",
    "                touch = random.choice(patterns['personal_academic'])\n",
    "                current_sentence = f\"{touch} {current_sentence.lower()}\"\n",
    "            elif genre_key == 'creative' and 'personal_expression' in patterns:\n",
    "                touch = random.choice(patterns['personal_expression'])\n",
    "                current_sentence = f\"{touch} {current_sentence.lower()}\"\n",
    "            elif genre_key == 'tech' and 'personal_experience' in patterns:\n",
    "                touch = random.choice(patterns['personal_experience'])\n",
    "                current_sentence = f\"{touch} {current_sentence.lower()}\"\n",
    "        \n",
    "        # Add conversational elements naturally (15% chance)\n",
    "        elif random.random() < 0.15 * intensity:\n",
    "            if genre_key == 'education' and 'conversational_academic' in patterns:\n",
    "                conv = random.choice(patterns['conversational_academic'])\n",
    "                current_sentence = current_sentence.replace(',', f', {conv},', 1)\n",
    "            elif genre_key == 'creative' and 'conversational_flow' in patterns:\n",
    "                conv = random.choice(patterns['conversational_flow'])\n",
    "                words = current_sentence.split()\n",
    "                if len(words) > 4:\n",
    "                    pos = random.randint(1, min(3, len(words)-1))\n",
    "                    words.insert(pos, f\"{conv},\")\n",
    "                    current_sentence = ' '.join(words)\n",
    "            elif genre_key == 'tech' and 'informal_connectors' in patterns:\n",
    "                conv = random.choice(patterns['informal_connectors'])\n",
    "                current_sentence = f\"{conv} {current_sentence.lower()}\"\n",
    "        \n",
    "        # Add appropriate uncertainty/hedging (10% chance)\n",
    "        elif random.random() < 0.1 * intensity:\n",
    "            if genre_key == 'education' and 'uncertainty_academic' in patterns:\n",
    "                hedge = random.choice(patterns['uncertainty_academic'])\n",
    "                current_sentence = current_sentence.replace(' is ', f' {hedge} ', 1)\n",
    "            elif genre_key == 'creative' and 'creative_uncertainty' in patterns:\n",
    "                hedge = random.choice(patterns['creative_uncertainty'])\n",
    "                current_sentence = current_sentence.replace(' is ', f' is {hedge} ', 1)\n",
    "            elif genre_key == 'tech' and 'uncertainty_tech' in patterns:\n",
    "                hedge = random.choice(patterns['uncertainty_tech'])\n",
    "                current_sentence = current_sentence.replace(' will ', f' {hedge} will ', 1)\n",
    "        \n",
    "        modified_sentences.append(current_sentence)\n",
    "    \n",
    "    if not modified_sentences:\n",
    "        return text\n",
    "        \n",
    "    # Join as single paragraph - NO bullet points or formatting\n",
    "    result = '. '.join(modified_sentences)\n",
    "    if not result.endswith('.'):\n",
    "        result += '.'\n",
    "    \n",
    "    # Add realistic typos sparingly (3% chance for subtle, 8% for high)\n",
    "    typo_chance = 0.03 if intensity < 0.8 else 0.08\n",
    "    if 'typos' in patterns and random.random() < typo_chance:\n",
    "        typo_pair = random.choice(patterns['typos'])\n",
    "        correct, typo = typo_pair\n",
    "        if correct.lower() in result.lower() and random.random() < 0.4:\n",
    "            result = re.sub(re.escape(correct), typo, result, count=1, flags=re.IGNORECASE)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def make_realistically_formal(text: str, genre: str, intensity: float = 0.8) -> str:\n",
    "    \"\"\"Make text slightly more formal without sounding artificial\"\"\"\n",
    "    genre_key = genre.lower()\n",
    "    if genre_key not in AI_MIMICRY_PATTERNS:\n",
    "        genre_key = 'education'\n",
    "    \n",
    "    patterns = AI_MIMICRY_PATTERNS[genre_key]\n",
    "    result = text\n",
    "    \n",
    "    # Very conservative approach - only make subtle changes\n",
    "    if 'objective_replacements' in patterns:\n",
    "        # Much lower replacement rate and only for obvious cases\n",
    "        replacement_chance = 0.15 if intensity < 0.8 else 0.25\n",
    "        for old, new in patterns['objective_replacements'][:2]:  # Only use first 2 replacements\n",
    "            if old.lower() in result.lower() and random.random() < replacement_chance:\n",
    "                result = re.sub(re.escape(old), new, result, count=1, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Remove only the most casual elements, very selectively\n",
    "    casual_removals = [\n",
    "        (\"you know\", \"\"),\n",
    "        (\"I mean\", \"\"),\n",
    "        (\"basically\", \"essentially\"),\n",
    "        (\"pretty much\", \"largely\"),\n",
    "        (\"kind of\", \"somewhat\")\n",
    "    ]\n",
    "    \n",
    "    for old, new in casual_removals:\n",
    "        if old in result.lower() and random.random() < 0.2:\n",
    "            result = re.sub(re.escape(old), new, result, count=1, flags=re.IGNORECASE)\n",
    "            result = re.sub(r'\\s+', ' ', result).strip()  # Clean up extra spaces\n",
    "    \n",
    "    # Only add formal elements very sparingly\n",
    "    if intensity > 0.8 and random.random() < 0.3:\n",
    "        # Add one formal transition word only\n",
    "        formal_transitions = [\"Furthermore,\", \"Additionally,\", \"Moreover,\"]\n",
    "        sentences = result.split('. ')\n",
    "        if len(sentences) > 2:\n",
    "            transition = random.choice(formal_transitions)\n",
    "            sentences[1] = f\"{transition} {sentences[1].lower()}\"\n",
    "            result = '. '.join(sentences)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def strategic_paraphrasing_realistic(text: str, target_type: str, genre: str, intensity: float) -> str:\n",
    "    \"\"\"Much more conservative paraphrasing that maintains natural flow\"\"\"\n",
    "    if groq_client is None:\n",
    "        return text\n",
    "    \n",
    "    try:\n",
    "        if target_type == \"humanize\":\n",
    "            # Keep these prompts the same as they work well\n",
    "            if intensity < 0.8:\n",
    "                prompts = {\n",
    "                    'education': \"Rewrite this academic text to sound like a student or researcher sharing their understanding. Add subtle personal touches like 'from what I understand' but keep it academic. Make it sound natural but scholarly.\",\n",
    "                    'creative': \"Rewrite this to sound like someone personally reflecting on the topic. Add gentle personal observations and natural language, but don't overdo it.\",\n",
    "                    'tech': \"Rewrite this technical content to sound like a developer sharing insights. Add casual phrases like 'I've noticed' but keep the technical accuracy.\"\n",
    "                }\n",
    "            else:\n",
    "                prompts = {\n",
    "                    'education': \"Rewrite this to sound like a knowledgeable person explaining the concept conversationally. Add personal insights and natural hesitations, making it sound like spoken academic discourse.\",\n",
    "                    'creative': \"Rewrite this with personal voice and emotional engagement, like someone passionate about the topic sharing their thoughts naturally.\",\n",
    "                    'tech': \"Rewrite this as if an experienced developer is explaining it conversationally, with personal examples and informal language, but maintaining technical accuracy.\"\n",
    "                }\n",
    "        else:  # ai_like - Make MUCH more conservative\n",
    "            if intensity < 0.8:  # Subtle - barely change anything\n",
    "                prompts = {\n",
    "                    'education': \"Make very minor edits to sound slightly more polished. Remove only the most casual phrases like 'you know' and 'I mean'. Keep the natural flow and don't add fancy words. Present as one paragraph.\",\n",
    "                    'creative': \"Clean up the most casual language slightly, but keep the personal voice. Just make it sound a bit more edited. Keep as one flowing paragraph.\",\n",
    "                    'tech': \"Remove only obvious casual phrases like 'basically' and 'you know'. Keep the technical content exactly the same. Make minimal changes as one paragraph.\"\n",
    "                }\n",
    "            else:  # High intensity - still very conservative\n",
    "                prompts = {\n",
    "                    'education': \"Edit to sound more polished but still natural. Replace only the most casual expressions with slightly more formal ones. Don't use academic jargon. Keep as one natural paragraph.\",\n",
    "                    'creative': \"Make this sound more edited and structured, but keep it readable and personal. Remove obvious casual language but don't make it academic. One paragraph only.\",\n",
    "                    'tech': \"Polish the language to sound more professional but not academic. Replace casual phrases with neutral alternatives. Keep technical accuracy. One paragraph format.\"\n",
    "                }\n",
    "        \n",
    "        prompt = prompts.get(genre.lower(), prompts['education'])\n",
    "        \n",
    "        response = groq_client.chat.completions.create(\n",
    "            model=\"llama-3.1-8b-instant\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": f\"{prompt} CRITICAL: Make MINIMAL changes. Don't overdo it. Keep it natural and readable. NO fancy vocabulary unless absolutely necessary.\"},\n",
    "                {\"role\": \"user\", \"content\": text}\n",
    "            ],\n",
    "            max_tokens=min(800, len(text.split()) * 2),\n",
    "            temperature=0.3  # Lower temperature for more conservative changes\n",
    "        )\n",
    "        \n",
    "        result = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # Ensure it's a single paragraph and not over-edited\n",
    "        result = re.sub(r'\\n+', ' ', result)\n",
    "        result = re.sub(r'\\*+.*?\\*+', '', result)\n",
    "        result = re.sub(r'#+\\s*', '', result)\n",
    "        result = re.sub(r'^\\d+\\.\\s*', '', result)\n",
    "        result = re.sub(r'^[-*•]\\s*', '', result)\n",
    "        result = re.sub(r'\\s+', ' ', result).strip()\n",
    "        \n",
    "        # Check if the result is too different (word count change > 50%)\n",
    "        orig_words = len(text.split())\n",
    "        new_words = len(result.split())\n",
    "        if abs(new_words - orig_words) / orig_words > 0.5:\n",
    "            print(f\"Paraphrasing too aggressive, using fallback\")\n",
    "            return text  # Return original if too changed\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Paraphrasing failed: {e}\")\n",
    "        return text\n",
    "\n",
    "def gentle_translation(text: str, intensity: float) -> str:\n",
    "    \"\"\"More conservative translation approach\"\"\"\n",
    "    if len(text) > 1200 or intensity < 0.7:  # Skip for long texts or low intensity\n",
    "        return text\n",
    "        \n",
    "    try:\n",
    "        text_to_translate = text[:800] if len(text) > 800 else text\n",
    "        \n",
    "        # Single hop for subtle, double hop for high intensity\n",
    "        if intensity < 0.8:\n",
    "            # Single hop: English -> Spanish -> English\n",
    "            step1 = GoogleTranslator(source='en', target='es').translate(text_to_translate)\n",
    "            if step1:\n",
    "                result = GoogleTranslator(source='es', target='en').translate(step1)\n",
    "                return result if result else text\n",
    "        else:\n",
    "            # Double hop: English -> German -> English\n",
    "            step1 = GoogleTranslator(source='en', target='de').translate(text_to_translate)\n",
    "            if step1:\n",
    "                result = GoogleTranslator(source='de', target='en').translate(step1)\n",
    "                return result if result else text\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Translation failed: {e}\")\n",
    "        return text\n",
    "    \n",
    "    return text\n",
    "\n",
    "# ===== IMPROVED ADVERSARIAL ATTACK STRATEGIES =====\n",
    "\n",
    "def realistic_adversarial_attack(text: str, source_label: str, genre: str, attack_type: str, intensity: float) -> Tuple[str, str]:\n",
    "    \"\"\"Execute realistic adversarial attacks based on genre-specific mapping\"\"\"\n",
    "    \n",
    "    source_lower = source_label.lower()\n",
    "    genre_lower = genre.lower()\n",
    "    \n",
    "    # Map broad genres to our categories\n",
    "    if 'education' in genre_lower or 'academic' in genre_lower or 'essay' in genre_lower or 'research' in genre_lower:\n",
    "        mapped_genre = 'education'\n",
    "    elif 'creative' in genre_lower or 'poem' in genre_lower or 'story' in genre_lower or 'history' in genre_lower:\n",
    "        mapped_genre = 'creative'  \n",
    "    elif 'tech' in genre_lower or 'article' in genre_lower or 'review' in genre_lower:\n",
    "        mapped_genre = 'tech'\n",
    "    else:\n",
    "        mapped_genre = 'education'  # default fallback\n",
    "    \n",
    "    if source_lower == 'ai':\n",
    "        # FALSE NEGATIVE attacks: Make AI text appear human-written\n",
    "        \n",
    "        if attack_type == \"PersonalAcademic\" and mapped_genre == 'education':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"humanize\", mapped_genre, intensity)\n",
    "            step2 = add_realistic_human_touches(step1, mapped_genre, intensity)\n",
    "            return step2, \"Personal_Academic_Voice\"\n",
    "        \n",
    "        elif attack_type == \"ConversationalAcademic\" and mapped_genre == 'education':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity)\n",
    "            step2 = gentle_translation(step1, intensity) if intensity > 0.7 else step1\n",
    "            return step2, \"Conversational_Academic\"\n",
    "        \n",
    "        elif attack_type == \"SubtleImperfection\" and mapped_genre == 'education':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity * 0.8)\n",
    "            return step1, \"Subtle_Academic_Imperfection\"\n",
    "        \n",
    "        elif attack_type == \"PersonalExpression\" and mapped_genre == 'creative':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"humanize\", mapped_genre, intensity)\n",
    "            step2 = add_realistic_human_touches(step1, mapped_genre, intensity)\n",
    "            return step2, \"Personal_Creative_Expression\"\n",
    "        \n",
    "        elif attack_type == \"EmotionalStyle\" and mapped_genre == 'creative':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity)\n",
    "            return step1, \"Emotional_Creative_Style\"\n",
    "        \n",
    "        elif attack_type == \"CreativeImperfection\" and mapped_genre == 'creative':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity * 0.7)\n",
    "            return step1, \"Creative_Human_Imperfection\"\n",
    "        \n",
    "        elif attack_type == \"TechExperience\" and mapped_genre == 'tech':\n",
    "            step1 = strategic_paraphrasing_realistic(text, \"humanize\", mapped_genre, intensity)\n",
    "            step2 = add_realistic_human_touches(step1, mapped_genre, intensity)\n",
    "            return step2, \"Technical_Experience_Voice\"\n",
    "        \n",
    "        elif attack_type == \"CasualTech\" and mapped_genre == 'tech':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity)\n",
    "            return step1, \"Casual_Technical_Style\"\n",
    "        \n",
    "        elif attack_type == \"TechImperfection\" and mapped_genre == 'tech':\n",
    "            step1 = add_realistic_human_touches(text, mapped_genre, intensity * 0.8)\n",
    "            return step1, \"Technical_Human_Imperfection\"\n",
    "    \n",
    "    else:  # source_lower == 'human'\n",
    "        # FALSE POSITIVE attacks: Make human text appear AI-generated (MUCH MORE CONSERVATIVE)\n",
    "        \n",
    "        if attack_type == \"FormalAcademic\" and mapped_genre == 'education':\n",
    "            # Only make very subtle changes\n",
    "            step1 = make_realistically_formal(text, mapped_genre, min(intensity, 0.6))\n",
    "            return step1, \"Subtle_Academic_Polish\"\n",
    "        \n",
    "        elif attack_type == \"ObjectiveRestructure\" and mapped_genre == 'education':\n",
    "            # Very light touch - just remove obvious personal language\n",
    "            step1 = make_realistically_formal(text, mapped_genre, min(intensity, 0.5))\n",
    "            return step1, \"Light_Objective_Edit\"\n",
    "        \n",
    "        elif attack_type == \"PrecisionRewrite\" and mapped_genre == 'education':\n",
    "            # Minimal paraphrasing with conservative prompts\n",
    "            if intensity > 0.7:\n",
    "                step1 = strategic_paraphrasing_realistic(text, \"ai_like\", mapped_genre, 0.6)\n",
    "            else:\n",
    "                step1 = make_realistically_formal(text, mapped_genre, 0.4)\n",
    "            return step1, \"Minimal_Precision_Edit\"\n",
    "        \n",
    "        elif attack_type == \"AnalyticalStyle\" and mapped_genre == 'creative':\n",
    "            # Just tone down emotional language slightly\n",
    "            step1 = make_realistically_formal(text, mapped_genre, min(intensity, 0.5))\n",
    "            return step1, \"Toned_Down_Creative\"\n",
    "        \n",
    "        elif attack_type == \"ObjectiveCreative\" and mapped_genre == 'creative':\n",
    "            # Very conservative creative editing\n",
    "            step1 = make_realistically_formal(text, mapped_genre, min(intensity, 0.4))\n",
    "            return step1, \"Conservative_Creative_Edit\"\n",
    "        \n",
    "        elif attack_type == \"FormalCreative\" and mapped_genre == 'creative':\n",
    "            if intensity > 0.7:\n",
    "                step1 = strategic_paraphrasing_realistic(text, \"ai_like\", mapped_genre, 0.5)\n",
    "            else:\n",
    "                step1 = text  # No change for low intensity\n",
    "            return step1, \"Light_Creative_Formal\"\n",
    "        \n",
    "        elif attack_type == \"TechnicalPrecision\" and mapped_genre == 'tech':\n",
    "            # Just clean up casual language\n",
    "            step1 = make_realistically_formal(text, mapped_genre, min(intensity, 0.6))\n",
    "            return step1, \"Tech_Language_Cleanup\"\n",
    "        \n",
    "        elif attack_type == \"SystematicApproach\" and mapped_genre == 'tech':\n",
    "            # Very minimal technical formalization\n",
    "            step1 = make_realistically_formal(text, mapped_genre, min(intensity, 0.5))\n",
    "            return step1, \"Minimal_Tech_Polish\"\n",
    "        \n",
    "        elif attack_type == \"FormalTech\" and mapped_genre == 'tech':\n",
    "            if intensity > 0.8:\n",
    "                step1 = strategic_paraphrasing_realistic(text, \"ai_like\", mapped_genre, 0.6)\n",
    "            else:\n",
    "                step1 = make_realistically_formal(text, mapped_genre, 0.4)\n",
    "            return step1, \"Conservative_Tech_Edit\"\n",
    "    \n",
    "    return text, \"No_Attack_Applied\"\n",
    "\n",
    "# ===== MAIN PROCESSING PIPELINE =====\n",
    "\n",
    "def process_adversarial_dataset(input_file: str, output_file: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main pipeline for generating realistic adversarial samples\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load dataset\n",
    "    try:\n",
    "        if input_file.endswith('.xlsx'):\n",
    "            df = pd.read_excel(input_file)\n",
    "        else:\n",
    "            df = pd.read_csv(input_file)\n",
    "        print(f\"Loaded dataset: {len(df)} samples\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Could not find {input_file}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Validate required columns\n",
    "    required_columns = ['original_text', 'source', 'genre']\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"Error: Missing required columns: {missing_columns}\")\n",
    "        print(f\"Available columns: {list(df.columns)}\")\n",
    "        return None\n",
    "    \n",
    "    # Clean and validate data\n",
    "    df = df.dropna(subset=['original_text', 'source', 'genre'])\n",
    "    df['source'] = df['source'].str.lower().str.strip()\n",
    "    df['genre'] = df['genre'].str.lower().str.strip()\n",
    "    \n",
    "    # Filter valid sources\n",
    "    valid_sources = df['source'].isin(['ai', 'human'])\n",
    "    if not valid_sources.all():\n",
    "        invalid_count = (~valid_sources).sum()\n",
    "        print(f\"Warning: {invalid_count} samples have invalid source labels. Filtering them out.\")\n",
    "        df = df[valid_sources].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Final dataset: {len(df)} samples\")\n",
    "    \n",
    "    # Initialize result columns\n",
    "    result_columns = {\n",
    "        'adversarial_text': \"\",\n",
    "        'attack_type': \"\",\n",
    "        'attack_technique': \"\",\n",
    "        'attack_target': \"\",\n",
    "        'original_length': 0,\n",
    "        'adversarial_length': 0,\n",
    "        'length_change_pct': 0.0,\n",
    "        'modification_intensity': \"\",\n",
    "        'expected_impact': \"\"\n",
    "    }\n",
    "    \n",
    "    for col, default_val in result_columns.items():\n",
    "        df[col] = default_val\n",
    "    \n",
    "    # Process each sample\n",
    "    print(\"Processing samples...\")\n",
    "    successful_attacks = 0\n",
    "    \n",
    "    for idx in df.index:\n",
    "        try:\n",
    "            original_text = str(df.at[idx, 'original_text'])\n",
    "            source = str(df.at[idx, 'source']).strip().lower()\n",
    "            genre = str(df.at[idx, 'genre']).strip().lower()\n",
    "            \n",
    "            # Skip if text is too short or too long\n",
    "            if len(original_text.split()) < 15:\n",
    "                df.at[idx, 'adversarial_text'] = original_text\n",
    "                df.at[idx, 'attack_type'] = \"Text_Too_Short\"\n",
    "                continue\n",
    "            elif len(original_text.split()) > 500:\n",
    "                df.at[idx, 'adversarial_text'] = original_text\n",
    "                df.at[idx, 'attack_type'] = \"Text_Too_Long\"  \n",
    "                continue\n",
    "            \n",
    "            # Map genre to our categories\n",
    "            if 'education' in genre or 'academic' in genre or 'essay' in genre or 'research' in genre:\n",
    "                mapped_genre = 'education'\n",
    "            elif 'creative' in genre or 'poem' in genre or 'story' in genre or 'history' in genre:\n",
    "                mapped_genre = 'creative'  \n",
    "            elif 'tech' in genre or 'article' in genre or 'review' in genre:\n",
    "                mapped_genre = 'tech'\n",
    "            else:\n",
    "                mapped_genre = 'education'  # default\n",
    "            \n",
    "            # Select genre-appropriate attack strategy\n",
    "            if source == 'ai':\n",
    "                available_attacks = GENRE_ATTACK_MAPPING[mapped_genre]['ai_to_human']\n",
    "                target = \"False_Negative\"\n",
    "            else:  # source == 'human'\n",
    "                available_attacks = GENRE_ATTACK_MAPPING[mapped_genre]['human_to_ai']\n",
    "                target = \"False_Positive\"\n",
    "            \n",
    "            attack_type = random.choice(available_attacks)\n",
    "            \n",
    "            # Determine intensity based on text characteristics\n",
    "            word_count = len(original_text.split())\n",
    "            if word_count > 100:\n",
    "                intensity = random.choice([0.6, 0.7, 0.8])  # More conservative for longer texts\n",
    "            else:\n",
    "                intensity = random.choice([0.7, 0.8, 0.9])  # Can be more aggressive for shorter texts\n",
    "            \n",
    "            # Execute realistic adversarial attack\n",
    "            adversarial_text, technique_used = realistic_adversarial_attack(\n",
    "                original_text, source, mapped_genre, attack_type, intensity\n",
    "            )\n",
    "            \n",
    "            # Calculate metrics\n",
    "            orig_length = len(original_text.split())\n",
    "            adv_length = len(adversarial_text.split())\n",
    "            length_change_pct = ((adv_length - orig_length) / orig_length) * 100\n",
    "            \n",
    "            # Determine modification intensity based on both length change and actual intensity\n",
    "            if intensity >= 0.8 and abs(length_change_pct) > 15:\n",
    "                intensity_label = \"High\"\n",
    "            elif intensity >= 0.7 or abs(length_change_pct) > 8:\n",
    "                intensity_label = \"Moderate\"\n",
    "            else:\n",
    "                intensity_label = \"Subtle\"\n",
    "            \n",
    "            # Expected impact assessment\n",
    "            if intensity_label == \"High\" and technique_used != \"No_Attack_Applied\":\n",
    "                impact = \"Strong_Realistic_Challenge\"\n",
    "            elif intensity_label == \"Moderate\":\n",
    "                impact = \"Moderate_Natural_Challenge\"\n",
    "            else:\n",
    "                impact = \"Subtle_Pattern_Shift\"\n",
    "            \n",
    "            # Store results\n",
    "            df.at[idx, 'adversarial_text'] = adversarial_text\n",
    "            df.at[idx, 'attack_type'] = attack_type\n",
    "            df.at[idx, 'attack_technique'] = technique_used\n",
    "            df.at[idx, 'attack_target'] = target\n",
    "            df.at[idx, 'original_length'] = orig_length\n",
    "            df.at[idx, 'adversarial_length'] = adv_length\n",
    "            df.at[idx, 'length_change_pct'] = round(length_change_pct, 2)\n",
    "            df.at[idx, 'modification_intensity'] = intensity_label\n",
    "            df.at[idx, 'expected_impact'] = impact\n",
    "            \n",
    "            if technique_used != \"No_Attack_Applied\":\n",
    "                successful_attacks += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {idx}: {e}\")\n",
    "            df.at[idx, 'adversarial_text'] = df.at[idx, 'original_text']\n",
    "            df.at[idx, 'attack_type'] = \"Processing_Error\"\n",
    "            df.at[idx, 'attack_technique'] = f\"Error: {str(e)[:50]}\"\n",
    "    \n",
    "    # Save results\n",
    "    if output_file is None:\n",
    "        base_name = input_file.rsplit('.', 1)[0]\n",
    "        output_file = f\"{base_name}_realistic_adversarial_results.xlsx\"\n",
    "    \n",
    "    try:\n",
    "        df.to_excel(output_file, index=False)\n",
    "        print(f\"Results saved to: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving file: {e}\")\n",
    "        return df\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    print(\"\\n=== REALISTIC ADVERSARIAL PIPELINE SUMMARY ===\")\n",
    "    print(f\"Total samples processed: {len(df)}\")\n",
    "    print(f\"Successful attacks: {successful_attacks}\")\n",
    "    print(f\"Success rate: {(successful_attacks/len(df)*100):.1f}%\")\n",
    "    \n",
    "    # Attack distribution by genre\n",
    "    print(f\"\\nGenre-specific attack distribution:\")\n",
    "    genre_attack = df.groupby(['genre', 'attack_type']).size().reset_index(name='count')\n",
    "    for genre in df['genre'].unique():\n",
    "        genre_data = genre_attack[genre_attack['genre'] == genre]\n",
    "        print(f\"\\n  {genre.upper()}:\")\n",
    "        for _, row in genre_data.iterrows():\n",
    "            print(f\"    {row['attack_type']}: {row['count']}\")\n",
    "    \n",
    "    # Target distribution\n",
    "    print(f\"\\nAttack target distribution:\")\n",
    "    target_counts = df['attack_target'].value_counts()\n",
    "    for target, count in target_counts.items():\n",
    "        print(f\"  {target}: {count}\")\n",
    "    \n",
    "    # Intensity distribution\n",
    "    print(f\"\\nModification intensity distribution:\")\n",
    "    intensity_counts = df['modification_intensity'].value_counts()\n",
    "    for intensity, count in intensity_counts.items():\n",
    "        print(f\"  {intensity}: {count}\")\n",
    "    \n",
    "    # Sample some results for quality check\n",
    "    print(f\"\\n=== SAMPLE TRANSFORMATIONS ===\")\n",
    "    sample_indices = df.sample(min(3, len(df))).index\n",
    "    for idx in sample_indices:\n",
    "        print(f\"\\nSample {idx} ({df.at[idx, 'genre']} - {df.at[idx, 'source']} -> {df.at[idx, 'attack_type']}):\")\n",
    "        print(f\"Original: {df.at[idx, 'original_text'][:100]}...\")\n",
    "        print(f\"Adversarial: {df.at[idx, 'adversarial_text'][:100]}...\")\n",
    "        print(f\"Technique: {df.at[idx, 'attack_technique']}\")\n",
    "    \n",
    "    print(f\"\\n=== READY FOR REALISTIC AI DETECTOR TESTING ===\")\n",
    "    print(\"✓ Genre-appropriate attacks applied\")\n",
    "    print(\"✓ Single paragraph format maintained\")\n",
    "    print(\"✓ Natural, realistic transformations\")\n",
    "    print(\"✓ Mimics real-world editing scenarios\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# ===== MAIN EXECUTION FUNCTION =====\n",
    "\n",
    "def run_realistic_adversarial_pipeline(input_file: str):\n",
    "    \"\"\"\n",
    "    Execute the improved adversarial pipeline for realistic AI detection testing\n",
    "    \n",
    "    Args:\n",
    "        input_file: Path to Excel/CSV file with columns: original_text, source, genre\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with original and realistically modified adversarial samples\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== REALISTIC ADVERSARIAL AI DETECTION PIPELINE ===\")\n",
    "    print(\"Purpose: Generate realistic adversarial samples mimicking real-world scenarios\")\n",
    "    print(\"Features:\")\n",
    "    print(\"• Genre-specific attack strategies\")\n",
    "    print(\"• Single paragraph format preservation\")\n",
    "    print(\"• Natural editing patterns\")\n",
    "    print(\"• Realistic intensity levels\")\n",
    "    print(f\"Input file: {input_file}\")\n",
    "    \n",
    "    # Process the dataset\n",
    "    result_df = process_adversarial_dataset(input_file)\n",
    "    \n",
    "    if result_df is not None:\n",
    "        print(\"\\n✓ Realistic pipeline completed successfully\")\n",
    "        print(\"✓ Natural transformations applied\")\n",
    "        print(\"✓ Ready for detector robustness evaluation\")\n",
    "        print(\"✓ Dataset prepared for real-world scenario testing\")\n",
    "        return result_df\n",
    "    else:\n",
    "        print(\"\\n✗ Pipeline failed - please check input file and requirements\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2503aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REALISTIC ADVERSARIAL AI DETECTION PIPELINE ===\n",
      "Purpose: Generate realistic adversarial samples mimicking real-world scenarios\n",
      "Features:\n",
      "• Genre-specific attack strategies\n",
      "• Single paragraph format preservation\n",
      "• Natural editing patterns\n",
      "• Realistic intensity levels\n",
      "Input file: xyzz.xlsx\n",
      "Loaded dataset: 8 samples\n",
      "Final dataset: 8 samples\n",
      "Processing samples...\n",
      "Results saved to: xyzz_realistic_adversarial_results.xlsx\n",
      "\n",
      "=== REALISTIC ADVERSARIAL PIPELINE SUMMARY ===\n",
      "Total samples processed: 8\n",
      "Successful attacks: 8\n",
      "Success rate: 100.0%\n",
      "\n",
      "Genre-specific attack distribution:\n",
      "\n",
      "  TECH:\n",
      "    CasualTech: 2\n",
      "    FormalTech: 4\n",
      "    TechExperience: 1\n",
      "    TechImperfection: 1\n",
      "\n",
      "Attack target distribution:\n",
      "  False_Positive: 4\n",
      "  False_Negative: 4\n",
      "\n",
      "Modification intensity distribution:\n",
      "  Moderate: 5\n",
      "  Subtle: 2\n",
      "  High: 1\n",
      "\n",
      "=== SAMPLE TRANSFORMATIONS ===\n",
      "\n",
      "Sample 5 (tech - ai -> TechExperience):\n",
      "Original: The horizon of emerging technologies in 2025 brims with innovations poised to reshape industries, ec...\n",
      "Adversarial: You know, I've been following the tech scene for a while now, and it's crazy to see how far we've co...\n",
      "Technique: Technical_Experience_Voice\n",
      "\n",
      "Sample 7 (tech - ai -> TechImperfection):\n",
      "Original: Neuralink, Elon Musk's neurotechnology venture, is pioneering brain-machine interfaces (BMIs) to mer...\n",
      "Adversarial: Neuralink, Elon Musk's neurotechnology venture, is pioneering brain-machine interfaces (BMIs) to mer...\n",
      "Technique: Technical_Human_Imperfection\n",
      "\n",
      "Sample 3 (tech - ai -> CasualTech):\n",
      "Original: Blockchain and smart contracts form the backbone of decentralized applications, merging cryptography...\n",
      "Adversarial: Blockchain and smart contracts form the backbone of decentralized applications, merging cryptography...\n",
      "Technique: Casual_Technical_Style\n",
      "\n",
      "=== READY FOR REALISTIC AI DETECTOR TESTING ===\n",
      "✓ Genre-appropriate attacks applied\n",
      "✓ Single paragraph format maintained\n",
      "✓ Natural, realistic transformations\n",
      "✓ Mimics real-world editing scenarios\n",
      "\n",
      "✓ Realistic pipeline completed successfully\n",
      "✓ Natural transformations applied\n",
      "✓ Ready for detector robustness evaluation\n",
      "✓ Dataset prepared for real-world scenario testing\n",
      "\n",
      "=== QUALITY CHECK ===\n",
      "\n",
      "High-intensity sample:\n",
      "Genre: tech\n",
      "Source: ai\n",
      "Attack: TechExperience\n",
      "Original: The horizon of emerging technologies in 2025 brims with innovations poised to reshape industries, economies, and daily life. Quantum computing leads, with IBM's 1,000+ qubit systems cracking complex simulations in hours, accelerating drug discovery and climate modeling. Unlike classical bits, qubits enable parallel processing, solving optimization problems infeasible today. AI integration deepens, evolving from generative models to agentic systems like OpenAI's o1, which reason step-by-step for scientific breakthroughs. Edge AI, processing data on devices, enhances privacy in IoT ecosystems, from smart cities to wearables. Biotech surges with CRISPR 2.0, editing genes precisely for personalized medicine; trials for curing sickle cell succeed, targeting 7 million globally. Synthetic biology engineers microbes for sustainable fuels, reducing carbon footprints. 6G networks promise terabit speeds and holographic communication, underpinning metaverses where AR/VR blurs digital-physical realms. Spatial computing, via Apple Vision Pro successors, revolutionizes remote work and education. Sustainable tech dominates: perovskite solar cells hit 30% efficiency, democratizing clean energy. Carbon capture scales via direct air methods, aiding net-zero goals. Robotics advances with soft, bio-inspired designs for eldercare and agriculture, boosting productivity amid labor shortages. Brain-computer interfaces, like Neuralink's Telepathy, restore mobility for paralyzed individuals, hinting at cognitive enhancements. Challenges include ethical AI governance—EU AI Act classifies risks—and cybersecurity against quantum threats. Talent shortages persist, but upskilling via platforms like Coursera bridges gaps. Outlook forecasts $15.7 trillion economic impact by 2030 per McKinsey, with Asia leading adoption. Investments pour in: $200 billion in AI alone last year. Yet, equitable access is key; digital divides must narrow to prevent exacerbating inequalities. These technologies converge, birthing autonomous systems—self-driving fleets optimizing logistics, AI-driven precision farming yielding 20% more crops. The outlook is optimistic yet cautious: innovation must align with human values, fostering resilience against disruptions like supply chain vulnerabilities exposed by pandemics. In this dynamic landscape, adaptability defines success. Emerging tech isn't just tools; it's the architect of tomorrow, demanding proactive policy, ethical frameworks, and inclusive strategies to harness its full potential for global prosperity.\n",
      "Modified: You know, I've been following the tech scene for a while now, and it's crazy to see how far we've come.. In 2025, we're on the cusp of some major breakthroughs that are going to change the game.. Quantum computing is leading the charge, with IBM's 1,000+ qubit systems that can solve complex problems in hours.. This is huge for fields like drug discovery and climate modeling.. Personally, the thing is, qubits can process information in parallel, which makes them way faster than classical computers.. From my experience, it's like having a team of super-smart researchers working on a problem simultaneously.. From my experience, artificial intelligence is also getting a major boost, moving from generative models to more advanced systems that can reason step-by-step.. OpenAI's o1 is a great example of this – it's like having a scientist in a box that can help us make new discoveries.. But here's the thing, and with edge ai, we're seeing more processing happening on devices themselves, which is great for privacy in iot ecosystems.. I mean, who wants their data being sent all over the place?. I've found that biotech is also making some incredible strides.. In my work, crispr 2.0 is allowing us to edit genes with unprecedented precision, which is going to revolutionize personalized medicine.. In my work, and with synthetic biology, we're engineering microbes to create sustainable fuels.. It's amazing to think about how far we've come in just a few years.. From my experience, of course, with all these advancements comes some challenges.. Plus, we need to make sure we're using these technologies responsibly, especially when it comes to ai governance.. From my experience, the eu ai act is a great example of this – it's all about classifying risks and making sure we're not creating systems that are too powerful for our own good.. In my work, and then there's the issue of cybersecurity.. In my work, with quantum computing, we're going to have to rethink how we protect our systems.. It's not just about keeping up with the latest threats; it's about being proactive and anticipating what's coming next.. In my work, but despite these challenges, the outlook is pretty optimistic.. Personally, mckinsey is predicting a $15.7 trillion economic impact by 2030, and asia is leading the charge.. Investments are pouring in – $200 billion in AI alone last year.. From my experience, however, we need to make sure that everyone has access to these technologies, or we risk exacerbating inequalities.. The thing is, these technologies are converging in some really exciting ways.. Working with this, we're seeing autonomous systems emerge, like self-driving fleets that can optimize logistics and ai-driven precision farming that can yield 20% more crops.. In my work, it's a whole new world, and we need to be adaptable to succeed.. Working with this, but here's the thing: innovation isn't just about tools; it's about values.. We need to make sure that we're using these technologies to create a better world, not just a more efficient one.. That means proactive policy, ethical frameworks, and inclusive strategies.. It's a big ask, but I think we're up to the challenge.\n",
      "Change: 61.04%\n",
      "\n",
      "Formatting quality check: 8/8 samples properly formatted\n",
      "✓ All samples maintain single paragraph format\n"
     ]
    }
   ],
   "source": [
    "# ===== USAGE EXAMPLE =====\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage - replace with your actual file\n",
    "    input_filename = \"xyzz.xlsx\"  # Your dataset file\n",
    "    results = run_realistic_adversarial_pipeline(input_filename)\n",
    "    \n",
    "    # Optional: Check specific transformations\n",
    "    if results is not None:\n",
    "        print(\"\\n=== QUALITY CHECK ===\")\n",
    "        # Show high-intensity transformations\n",
    "        high_intensity = results[results['modification_intensity'] == 'High']\n",
    "        if len(high_intensity) > 0:\n",
    "            print(f\"\\nHigh-intensity sample:\")\n",
    "            idx = high_intensity.index[0]\n",
    "            print(f\"Genre: {results.at[idx, 'genre']}\")\n",
    "            print(f\"Source: {results.at[idx, 'source']}\")\n",
    "            print(f\"Attack: {results.at[idx, 'attack_type']}\")\n",
    "            print(f\"Original: {results.at[idx, 'original_text']}\")\n",
    "            print(f\"Modified: {results.at[idx, 'adversarial_text']}\")\n",
    "            print(f\"Change: {results.at[idx, 'length_change_pct']}%\")\n",
    "        \n",
    "        # Check for any formatting issues\n",
    "        formatting_issues = 0\n",
    "        for idx in results.index:\n",
    "            adv_text = str(results.at[idx, 'adversarial_text'])\n",
    "            if ('*' in adv_text or '#' in adv_text or \n",
    "                adv_text.count('\\n') > 2 or '1.' in adv_text or '•' in adv_text):\n",
    "                formatting_issues += 1\n",
    "        \n",
    "        print(f\"\\nFormatting quality check: {len(results) - formatting_issues}/{len(results)} samples properly formatted\")\n",
    "        if formatting_issues > 0:\n",
    "            print(f\"⚠️  {formatting_issues} samples may have formatting artifacts\")\n",
    "        else:\n",
    "            print(\"✓ All samples maintain single paragraph format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff50c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Parrot)",
   "language": "python",
   "name": "parrot_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
